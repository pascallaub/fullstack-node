# Nginx √úbung: Kubernetes Deployment, Service, Rolling Update & Rollback

Dieses Verzeichnis enth√§lt die notwendigen Dateien und Anleitungen, um ein Nginx Deployment und einen Service in Kubernetes zu erstellen, ein Rolling Update durchzuf√ºhren und ein Rollback zu testen.

## Lernziele dieser Aufgabe:

Diese √úbung zielt darauf ab, dir praktische Erfahrungen mit grundlegenden Kubernetes-Konzepten zu vermitteln:

1.  **Deployment-Definition in YAML schreiben und verstehen:**

    - **Erkl√§rung:** Du lernst, wie man eine `Deployment`-Ressource definiert, die Kubernetes anweist, wie eine bestimmte Anzahl von Replikaten deiner Anwendung (Pods) erstellt und aktuell gehalten werden soll. Dies beinhaltet die Angabe des Container-Images, der Anzahl der Replikate und wie Pods f√ºr das Deployment identifiziert werden (Labels und Selektoren).
    - **In dieser √úbung:** Du erstellst `nginx-deployment.yaml`, um Nginx-Container zu deployen.

2.  **Service-Definition (Typ NodePort) in YAML schreiben und verstehen:**

    - **Erkl√§rung:** Du lernst, wie man eine `Service`-Ressource definiert, um einen stabilen Netzwerkendpunkt (IP-Adresse und Port) f√ºr deine Pods bereitzustellen. Der Typ `NodePort` macht deine Anwendung auf einem spezifischen Port auf jedem Node deines Clusters zug√§nglich, sodass du von au√üerhalb des Clusters darauf zugreifen kannst.
    - **In dieser √úbung:** Du erstellst `nginx-service.yaml`, um dein Nginx-Deployment √ºber einen NodePort extern erreichbar zu machen.

3.  **Verstehen, wie ein Deployment Pods √ºber Labels selektiert und managt:**

    - **Erkl√§rung:** Labels sind Schl√ºssel-Wert-Paare, die an Kubernetes-Objekte angeh√§ngt werden. Selektoren erm√∂glichen es, Objekte basierend auf diesen Labels auszuw√§hlen. Deployments verwenden Selektoren, um zu wissen, welche Pods sie verwalten sollen.
    - **In dieser √úbung:** Das Deployment `nginx-app-deployment` verwendet `spec.selector.matchLabels` mit `app: nginx-example`, um Pods zu finden, die in `spec.template.metadata.labels` ebenfalls `app: nginx-example` haben.

4.  **Verstehen, wie ein Service Pods √ºber Labels selektiert und den Traffic weiterleitet:**

    - **Erkl√§rung:** √Ñhnlich wie Deployments verwenden Services Selektoren, um die Gruppe von Pods zu identifizieren, an die der Netzwerkverkehr weitergeleitet werden soll.
    - **In dieser √úbung:** Der Service `nginx-app-service` verwendet `spec.selector` mit `app: nginx-example`, um Anfragen an die Nginx-Pods weiterzuleiten, die vom Deployment verwaltet werden.

5.  **Ein Deployment und einen Service mit `kubectl apply` deployen:**

    - **Erkl√§rung:** Du lernst den grundlegenden `kubectl apply -f <dateiname>.yaml` Befehl kennen, um Konfigurationen aus YAML-Dateien auf deinen Kubernetes-Cluster anzuwenden und Ressourcen zu erstellen oder zu aktualisieren.
    - **In dieser √úbung:** Du wendest `nginx-deployment.yaml` und `nginx-service.yaml` an.

6.  **Die Skalierungs-, Rolling Update- und Rollback-Funktionen von Deployments praktisch anwenden:**

    - **Erkl√§rung:**
      - **Skalierung:** Die F√§higkeit, die Anzahl der laufenden Pods einfach zu erh√∂hen oder zu verringern.
      - **Rolling Update:** Eine Strategie, um eine neue Version deiner Anwendung schrittweise auszurollen, indem alte Pods nach und nach durch neue ersetzt werden, ohne Ausfallzeit.
      - **Rollback:** Die M√∂glichkeit, schnell zu einer vorherigen, stabilen Version deiner Anwendung zur√ºckzukehren, falls Probleme mit der neuen Version auftreten.
    - **In dieser √úbung:** Du √§nderst das Image im Deployment, um ein Rolling Update auszul√∂sen, und verwendest `kubectl rollout undo`, um ein Rollback durchzuf√ºhren.

7.  **Den Prozess eines Rolling Updates und Rollbacks in Kubernetes beobachten und verstehen:**

    - **Erkl√§rung:** Du lernst, Befehle wie `kubectl rollout status` und `kubectl get pods -w` zu verwenden, um den Fortschritt von Updates und Rollbacks in Echtzeit zu verfolgen und zu verstehen, wie Kubernetes Pods beendet und startet.
    - **In dieser √úbung:** Du wirst diese Befehle verwenden, um die Aktualisierungs- und Wiederherstellungsprozesse zu beobachten.

8.  **Die Kommunikation zwischen Service und Pods √ºber den Label-Selektor verifizieren:**
    - **Erkl√§rung:** Du stellst sicher, dass der Service den Traffic korrekt an die vom Deployment verwalteten Pods leitet, indem du die Anwendung √ºber den NodePort des Services aufrufst.
    - **In dieser √úbung:** Der erfolgreiche Aufruf der Nginx-Seite im Browser best√§tigt diese Kommunikation.

## Verzeichnisstruktur

```
nginx-√ºbung/
‚îú‚îÄ‚îÄ nginx-app-v1/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ nginx-app-v2/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ nginx-deployment.yaml
‚îú‚îÄ‚îÄ nginx-service.yaml
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ nginx1.png
‚îÇ   ‚îú‚îÄ‚îÄ nginx2.png
‚îÇ   ‚îî‚îÄ‚îÄ update.png
‚îî‚îÄ‚îÄ README.md               # Diese Datei
```

## Anleitung:

### 1. Voraussetzungen pr√ºfen & Lokales Cluster starten

- Stelle sicher, dass Docker installiert und l√§uft.
- Stelle sicher, dass `kubectl` installiert ist und auf dein lokales Kubernetes Cluster zeigt (Docker Desktop Kubernetes, Minikube oder Kind sollten laufen und `kubectl get nodes` sollte erfolgreich sein).
- Stelle sicher, dass du bei Docker Hub angemeldet bist (`docker login`). Du wirst deine Images dorthin pushen. Dein Docker Hub Username ist `mephisto1339` (dieser ist bereits in `nginx-deployment.yaml` eingetragen).

### 2. Vorbereitung: Zwei Versionen eines Nginx Images bauen & pushen

Die Verzeichnisse `nginx-app-v1` und `nginx-app-v2` enthalten jeweils eine `index.html` und ein `Dockerfile`.

- `nginx-app-v1/index.html`: Zeigt "Hello from Nginx - Version 1" mit hellblauem Hintergrund.
- `nginx-app-v2/index.html`: Zeigt "Hello from Nginx - Version 2" mit hellgr√ºnem Hintergrund.
- Die `Dockerfile`s kopieren die jeweilige `index.html` in ein `nginx:latest` Image.

**Befehle (aus dem Hauptverzeichnis `node-container` ausf√ºhren oder Pfade anpassen, wenn du dich bereits in `kubernetes/nginx-√ºbung` befindest):**

1.  **Baue die zwei Images:**

    ```bash
    # Wenn du im Verzeichnis 'node-container' bist:
    docker build -t mephisto1339/nginx-example:v1 ./kubernetes/nginx-√ºbung/nginx-app-v1
    docker build -t mephisto1339/nginx-example:v2 ./kubernetes/nginx-√ºbung/nginx-app-v2

    # Wenn du bereits in 'node-container/kubernetes/nginx-√ºbung' bist:
    # docker build -t mephisto1339/nginx-example:v1 ./nginx-app-v1
    # docker build -t mephisto1339/nginx-example:v2 ./nginx-app-v2
    ```

2.  **Pushe die beiden Images auf Docker Hub:**
    ```bash
    docker push mephisto1339/nginx-example:v1
    docker push mephisto1339/nginx-example:v2
    ```

### 3. Kubernetes Manifeste erstellen (YAML)

Die Manifeste sind bereits in diesem Verzeichnis (`kubernetes/nginx-√ºbung/`) vorhanden:

- **`nginx-deployment.yaml`**:
  - Definiert ein Deployment namens `nginx-app-deployment`.
  - Startet mit 3 Replikaten.
  - Verwendet das Label `app: nginx-example` f√ºr den Selector und die Pod-Vorlage.
  - Nutzt initial das Image `mephisto1339/nginx-example:v1`.
  - Der Container lauscht auf Port `80`.
- **`nginx-service.yaml`**:
  - Definiert einen Service namens `nginx-app-service`.
  - Ist vom Typ `NodePort`.
  - Selektiert Pods mit dem Label `app: nginx-example`.
  - Mappt den Service-Port `80` auf den Container-Port `80`.

### 4. Anwendung in Kubernetes deployen

1.  Navigiere im Terminal in dieses Verzeichnis (`kubernetes/nginx-√ºbung/`).
2.  Deploye das Deployment und den Service:
    ```bash
    kubectl apply -f nginx-deployment.yaml
    kubectl apply -f nginx-service.yaml
    ```

### 5. Initiales Deployment √ºberpr√ºfen

1.  **√úberpr√ºfe den Status deines Deployments:**

    ```bash
    kubectl get deployment nginx-app-deployment
    ```

    Warte, bis 3/3 Replikate als `READY` angezeigt werden.

2.  **√úberpr√ºfe den Status der Pods:**

    ```bash
    kubectl get pods -l app=nginx-example
    ```

    Warte, bis alle 3 Pods den Status `Running` haben.

3.  **√úberpr√ºfe den Status deines Service und finde den zugewiesenen NodePort:**

    ```bash
    kubectl get service nginx-app-service
    ```

    Notiere den `NodePort` aus der Ausgabe (z.B. `80:31324/TCP`, hier w√§re `31324` der NodePort).

4.  **Finde die IP-Adresse deines Worker Nodes:**
    (Bei Minikube: `minikube ip`. Bei Docker Desktop ist es oft `localhost` oder die IP der Docker Desktop VM.)

    ```bash
    kubectl get nodes -o wide
    ```

    Notiere die `INTERNAL-IP` eines Nodes. **Wenn du Docker Desktop verwendest und Kubernetes dort l√§uft, verwende f√ºr den n√§chsten Schritt `localhost` als Node-IP.**

5.  **√ñffne deinen Browser** und rufe `http://<Node-IP>:<NodePort>` auf (z.B. `http://localhost:31324` bei Docker Desktop, oder `http://<INTERNAL-IP-des-Nodes>:<NodePort>` bei anderen Setups). Du solltest die Nginx-Seite deiner **Version 1** sehen (hellblauer Hintergrund).

    ![Nginx Version 1](./nginx1.png)

### 6. Rolling Update durchf√ºhren

1.  **Bearbeite die Datei `nginx-deployment.yaml`** in diesem Verzeichnis. √Ñndere das Container-Image von:
    `image: mephisto1339/nginx-example:v1`
    zu:
    `image: mephisto1339/nginx-example:v2`
    Speichere die Datei.

2.  **Wende die ge√§nderte Deployment-Definition an:**

    ```bash
    kubectl apply -f nginx-deployment.yaml
    ```

3.  **Beobachte den Rollout-Prozess:**

    ```bash
    kubectl rollout status deployment/nginx-app-deployment
    ```

    (Zeigt den Fortschritt an, bis "deployment "nginx-app-deployment" successfully rolled out" erscheint.)
    Du kannst auch parallel in einem anderen Terminal beobachten:

    ```bash
    kubectl get pods -l app=nginx-example -w
    ```

    (Sieh zu, wie die alten Pods (`v1`) beendet und neue Pods (`v2`) gestartet werden.)

    Ungef√§hr so sollte die Ausgabe von `kubectl get pods -w` w√§hrend des Updates aussehen:
    ![Rolling Update Pods](./update.png)

4.  Wenn der Rollout abgeschlossen ist, **rufe die Adresse im Browser neu auf** (`http://<Node-IP>:<NodePort>`). Du solltest nun die Nginx-Seite deiner **Version 2** sehen (hellgr√ºner Hintergrund). Lade die Seite ggf. mehrmals, um sicherzustellen, dass alle Pods aktualisiert wurden.

    ![Nginx Version 2](./nginx2.png)

### 7. Rollback durchf√ºhren

Angenommen, Version 2 hat Probleme und du m√∂chtest zur vorherigen Version zur√ºckkehren.

1.  **F√ºhre ein Rollback zum vorherigen Deployment durch:**

    ```bash
    kubectl rollout undo deployment/nginx-app-deployment
    ```

2.  **Beobachte den Rollback-Prozess:**

    ```bash
    kubectl rollout status deployment/nginx-app-deployment
    ```

    Und/oder:

    ```bash
    kubectl get pods -l app=nginx-example -w
    ```

3.  Wenn der Rollback abgeschlossen ist, **rufe die Adresse im Browser neu auf**. Du solltest wieder die Nginx-Seite deiner **Version 1** sehen (hellblauer Hintergrund).

### 8. Aufr√§umen

L√∂sche das Deployment und den Service, um die erstellten Ressourcen zu entfernen.

1.  **L√∂sche die Ressourcen:**

    ```bash
    kubectl delete -f nginx-deployment.yaml
    kubectl delete -f nginx-service.yaml
    ```

    Oder zusammen:

    ```bash
    kubectl delete -f nginx-deployment.yaml,nginx-service.yaml
    ```

2.  **√úberpr√ºfe, ob die Ressourcen entfernt wurden:**

    ```bash
    kubectl get deployment,service,pods -l app=nginx-example
    ```

    Sollte "No resources found" oder √Ñhnliches f√ºr die jeweiligen Typen anzeigen.

3.  **Stoppe dein lokales Cluster** (optional, aber empfohlen, um Ressourcen zu sparen):
    - F√ºr Minikube: `minikube stop`
    - F√ºr Docker Desktop: Deaktiviere Kubernetes in den Docker Desktop Einstellungen.

## Reflexion

### Warum ist ein Deployment in Kubernetes nicht einfach nur eine etwas andere Version von `docker run` mit `--restart=always`?

Ein `docker run --restart=always` Befehl k√ºmmert sich nur um einen einzelnen Container auf einem einzelnen Host. Wenn dieser Container ausf√§llt, wird er neu gestartet. Das ist zwar n√ºtzlich, aber ein Kubernetes Deployment, wie unser `nginx-app-deployment`, bietet weit mehr:

- **Deklarativer Zustand:** Wir definieren in der `nginx-deployment.yaml`, _wie viele_ Replikate unserer Nginx-Anwendung laufen sollen (z.B. 3) und _welche Version_ (z.B. `mephisto1339/nginx-example:v1`). Kubernetes sorgt dann daf√ºr, diesen Zustand aktiv aufrechtzuerhalten.
- **Skalierbarkeit:** Wir k√∂nnen die Anzahl der `replicas` einfach √§ndern, und das Deployment k√ºmmert sich darum, Pods hinzuzuf√ºgen oder zu entfernen.
- **Rolling Updates & Rollbacks:** Wie in der √úbung gesehen, erm√∂glicht ein Deployment kontrollierte Updates auf eine neue Version (z.B. von `v1` auf `v2` unseres Nginx-Images) und bei Bedarf ein Zur√ºckrollen zur vorherigen Version, ohne dass der Service komplett ausf√§llt.
- **Selbstheilung √ºber mehrere Pods:** F√§llt einer der Nginx-Pods aus, startet das Deployment automatisch einen neuen, um die gew√ºnschte Anzahl an Replikaten sicherzustellen.
- **Verwaltung von Pod-Vorlagen:** Das Deployment definiert eine Vorlage (`spec.template`) f√ºr die Erstellung der Pods, inklusive Container-Images, Ports und Labels.

Ein Deployment ist also ein intelligenter Controller, der eine ganze Gruppe von Anwendungsinstanzen managt, deren Lebenszyklus √ºberwacht und f√ºr Hochverf√ºgbarkeit und einfache Aktualisierungen sorgt ‚Äì weit √ºber das hinaus, was ein einfacher Docker-Neustart leisten kann.

### Was tut das Deployment, wenn ein Pod pl√∂tzlich verschwindet ‚Äì und warum ist das nicht einfach nur Magie?

Wenn einer unserer Nginx-Pods (z.B. einer der drei Replikate des `nginx-app-deployment`) pl√∂tzlich verschwindet ‚Äì sei es durch einen Node-Ausfall, einen internen Fehler im Pod oder manuelles L√∂schen ‚Äì passiert Folgendes:

1.  Der **Deployment Controller** √ºberwacht kontinuierlich die Anzahl der laufenden Pods, die zu seinem `selector` (in unserem Fall `app: nginx-example`) passen.
2.  Er stellt fest, dass die aktuelle Anzahl der laufenden Pods (z.B. 2) nicht mehr mit der in `spec.replicas` definierten gew√ºnschten Anzahl (z.B. 3) √ºbereinstimmt.
3.  Um diesen Unterschied auszugleichen und den deklarierten Zustand wiederherzustellen, weist der Deployment Controller das zugeh√∂rige **ReplicaSet** an, einen neuen Pod gem√§√ü der `spec.template` des Deployments zu erstellen.
4.  Ein neuer Nginx-Pod wird gestartet, sodass wieder die gew√ºnschten 3 Replikate laufen.

Das ist keine Magie, sondern das Ergebnis der kontinuierlichen **Abgleichschleife (Reconciliation Loop)**, die ein Kernprinzip von Kubernetes ist. Controller arbeiten st√§ndig daran, den tats√§chlichen Zustand des Clusters mit dem vom Benutzer deklarierten gew√ºnschten Zustand in Einklang zu bringen.

### Was konntest du beim Rolling Update mit `kubectl get pods -w` beobachten ‚Äì und wie wird hier sichergestellt, dass es keinen kompletten Ausfall gibt?

Beim Rolling Update von `mephisto1339/nginx-example:v1` auf `v2` konnte man mit `kubectl get pods -l app=nginx-example -w` Folgendes beobachten:

1.  Zuerst liefen drei Pods mit dem alten Image (`v1`).
2.  Nach dem `kubectl apply -f nginx-deployment.yaml` mit dem ge√§nderten Image-Tag begann Kubernetes, neue Pods mit dem `v2`-Image zu erstellen. Man sah einen neuen Pod im Status `ContainerCreating`, dann `Running`.
3.  Sobald ein neuer `v2`-Pod lief und bereit war (`READY 1/1`), begann Kubernetes, einen der alten `v1`-Pods zu beenden. Man sah einen `v1`-Pod in den Status `Terminating` wechseln und schlie√ülich verschwinden.
4.  Dieser Prozess wiederholte sich: Ein neuer `v2`-Pod wurde gestartet, dann ein alter `v1`-Pod beendet, bis alle drei laufenden Pods die neue `v2`-Version hatten.

So wird sichergestellt, dass es keinen kompletten Ausfall gibt:

- **Schrittweise Aktualisierung:** Nicht alle alten Pods werden gleichzeitig gestoppt.
- **Verf√ºgbarkeit wird aufrechterhalten:** Es wird standardm√§√üig darauf geachtet, dass immer eine bestimmte Mindestanzahl an Pods verf√ºgbar ist (gesteuert durch `maxUnavailable`) und nicht zu viele neue Pods gleichzeitig gestartet werden (gesteuert durch `maxSurge` in der Deployment-Strategie). In unserer √úbung mit 3 Replikaten und den Standardeinstellungen bedeutet das typischerweise, dass ein neuer Pod hochf√§hrt, bevor ein alter heruntergefahren wird, oder dass maximal ein Pod nicht verf√ºgbar ist. Dadurch kann der `nginx-app-service` den Traffic weiterhin an die verbleibenden laufenden Pods (alte oder neue) leiten.

### Wie sorgt der Kubernetes-Service daf√ºr, dass dein Browser-Ping (√ºber NodePort) den richtigen Pod trifft ‚Äì selbst wenn sich gerade ein Update vollzieht?

Der `nginx-app-service` sorgt so daf√ºr, dass Anfragen √ºber den NodePort (z.B. `http://localhost:31324`) auch w√§hrend eines Updates die richtigen, laufenden Nginx-Pods erreichen:

1.  **Label-Selektor:** Der Service ist in seiner YAML-Definition (`nginx-service.yaml`) mit einem `selector` konfiguriert, in unserem Fall `app: nginx-example`.
2.  **Endpoint-√úberwachung:** Kubernetes (genauer gesagt, der Endpoints Controller) √ºberwacht kontinuierlich alle Pods im Cluster. Es identifiziert alle Pods, die die Labels des Service-Selektors tragen (also `app: nginx-example`) UND die bereit sind, Traffic zu empfangen (d.h., sie sind `Running` und haben ihre Readiness-Probe bestanden, falls konfiguriert).
3.  **Dynamische Endpoint-Liste:** Der Service h√§lt eine dynamische Liste dieser bereiten Pods als seine "Endpoints". Wenn ein neuer `v2`-Pod w√§hrend des Rolling Updates startet und bereit ist, wird er dieser Liste hinzugef√ºgt. Wenn ein alter `v1`-Pod terminiert wird, wird er aus der Liste entfernt.
4.  **Load Balancing:** Wenn eine Anfrage beim Service (√ºber den NodePort) ankommt, leitet der Service diese Anfrage per Load Balancing an einen der _aktuell in seiner Endpoint-Liste gef√ºhrten, bereiten Pods_ weiter.

Da die Endpoint-Liste dynamisch aktualisiert wird, um nur die gesunden und bereiten Pods (egal ob `v1` oder `v2` w√§hrend des √úbergangs) zu enthalten, stellt der Service sicher, dass Anfragen immer an eine funktionierende Instanz unserer Nginx-Anwendung geleitet werden.

### In der Deployment-YAML: Welche Angaben betreffen die Pod-Vorlage, und welche regeln das Verhalten des Deployments (z.B. Skalierung, Strategie)?

In unserer `nginx-deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-app-deployment # Name des Deployments
spec: # Hier beginnt die Spezifikation des Deployments
  replicas: 3 # ‚öôÔ∏è Verhalten des Deployments: Wie viele Pods sollen laufen?
  selector: # Verhalten des Deployments: Welche Pods geh√∂ren zu diesem Deployment?
    matchLabels:
      app: nginx-example
  # strategy: (implizit RollingUpdate mit Defaults) # Verhalten des Deployments
  template: #  Pod-Vorlage: Wie soll jeder einzelne Pod aussehen?
    metadata: # Metadaten f√ºr die Pods, die erstellt werden
      labels: # Labels f√ºr die Pods (m√ºssen zum selector passen)
        app: nginx-example
    spec: # Spezifikation f√ºr die Pods
      containers: # üì¶ Definition der Container innerhalb des Pods
        - name: nginx
          image: mephisto1339/nginx-example:v1 # Welches Image?
          ports:
            - containerPort: 80 # Welchen Port stellt der Container bereit?
```

- **Pod-Vorlage (`spec.template`)**: Alles innerhalb von `spec.template` definiert, wie ein einzelner Pod, der von diesem `nginx-app-deployment` verwaltet wird, aufgebaut sein soll. Das umfasst:

  - `spec.template.metadata.labels`: Die Labels (`app: nginx-example`), die jedem Pod gegeben werden.
  - `spec.template.spec.containers`: Die Definition der Container üì¶ innerhalb des Pods, hier unser `nginx`-Container mit dem Image (`mephisto1339/nginx-example:v1`) und dem `containerPort: 80`.

- **Verhalten des Deployments (direkt unter `spec`, au√üerhalb von `template`)**: Diese Angaben steuern, wie das `nginx-app-deployment` selbst agiert:
  - `spec.replicas: 3` ‚öôÔ∏è: Gibt an, dass das Deployment drei identische Pods (basierend auf der Vorlage) erstellen und verwalten soll.
  - `spec.selector.matchLabels`: Definiert, welche Pods (die mit dem Label `app: nginx-example`) zu diesem Deployment geh√∂ren und von ihm verwaltet werden.
  - `spec.strategy` (auch wenn in unserer Datei nicht explizit mit allen Details aufgef√ºhrt, wird standardm√§√üig `RollingUpdate` verwendet): Bestimmt, wie Updates durchgef√ºhrt werden (z.B. schrittweise Ersetzung der Pods).

### Was passiert mit den Pods, wenn du das Deployment l√∂schst ‚Äì und warum ist das Verhalten logisch?

Wenn du das `nginx-app-deployment` l√∂schst (z.B. mit `kubectl delete -f nginx-deployment.yaml`):

1.  Das Kubernetes-System erh√§lt die Anweisung, die Ressource `Deployment` mit dem Namen `nginx-app-deployment` zu entfernen.
2.  Der Deployment Controller erkennt, dass dieses Deployment nicht mehr existieren soll.
3.  Da das Deployment die "Blaupause" und der Manager f√ºr die Nginx-Pods war, die das Label `app: nginx-example` tragen, ist die logische Konsequenz, dass auch diese verwalteten Pods nicht mehr ben√∂tigt werden.
4.  Das Deployment (bzw. das von ihm gesteuerte ReplicaSet) skaliert die Anzahl der zugeh√∂rigen Pods auf 0 herunter.
5.  Die Nginx-Pods erhalten ein Terminationssignal, werden ordnungsgem√§√ü heruntergefahren und schlie√ülich gel√∂scht.

Dieses Verhalten ist logisch, weil Kubernetes einem **deklarativen Ansatz** folgt. Du deklarierst den gew√ºnschten Zustand (z.B. "ich m√∂chte ein Deployment namens `nginx-app-deployment`, das 3 Nginx-Pods betreibt"). Wenn du diese Deklaration (das Deployment-Objekt) l√∂schst, sagst du Kubernetes: "Ich m√∂chte diesen Zustand nicht mehr." Kubernetes entfernt dann alle Ressourcen (die Pods), die es erstellt hat, um diesen nicht mehr gew√ºnschten Zustand zu erf√ºllen. Es r√§umt sozusagen hinter sich auf, um das System konsistent zu halten.
